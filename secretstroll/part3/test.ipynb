{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No IPv4 address found on anpi2 !\n",
      "WARNING: No IPv4 address found on anpi1 !\n",
      "WARNING: more No IPv4 address found on anpi0 !\n",
      "Reading traces...: 100%|██████████| 5000/5000 [00:32<00:00, 153.37it/s]\n",
      "Extracting features...: 100%|██████████| 100/100 [00:11<00:00,  8.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import data_sanitize\n",
    "import importlib\n",
    "importlib.reload(data_sanitize)\n",
    "import pandas as pd\n",
    "\n",
    "traces = data_sanitize.get_traces()\n",
    "training_data = data_sanitize.get_training_data(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid</th>\n",
       "      <th>num_outgoing</th>\n",
       "      <th>num_incoming</th>\n",
       "      <th>outgoing_ratio</th>\n",
       "      <th>incoming_ratio</th>\n",
       "      <th>outgoing_bytes</th>\n",
       "      <th>incoming_bytes</th>\n",
       "      <th>avg_outgoing_freq</th>\n",
       "      <th>avg_incoming_freq</th>\n",
       "      <th>std_outgoing_freq</th>\n",
       "      <th>...</th>\n",
       "      <th>std_outgoing_bytes</th>\n",
       "      <th>std_incoming_bytes</th>\n",
       "      <th>min_outgoing_bytes</th>\n",
       "      <th>min_incoming_bytes</th>\n",
       "      <th>max_outgoing_bytes</th>\n",
       "      <th>max_incoming_bytes</th>\n",
       "      <th>min_outgoing_freq</th>\n",
       "      <th>min_incoming_freq</th>\n",
       "      <th>max_outgoing_freq</th>\n",
       "      <th>max_incoming_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.541379</td>\n",
       "      <td>0.458621</td>\n",
       "      <td>414308.0</td>\n",
       "      <td>40486.0</td>\n",
       "      <td>0.042547</td>\n",
       "      <td>0.050559</td>\n",
       "      <td>0.078255</td>\n",
       "      <td>...</td>\n",
       "      <td>2958.765773</td>\n",
       "      <td>376.784956</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14532.0</td>\n",
       "      <td>2948.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.277571</td>\n",
       "      <td>0.320129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.519886</td>\n",
       "      <td>0.480114</td>\n",
       "      <td>417216.0</td>\n",
       "      <td>43430.0</td>\n",
       "      <td>0.182481</td>\n",
       "      <td>0.197864</td>\n",
       "      <td>0.517925</td>\n",
       "      <td>...</td>\n",
       "      <td>2576.499100</td>\n",
       "      <td>351.063178</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14532.0</td>\n",
       "      <td>2948.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>3.837083</td>\n",
       "      <td>3.837594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.538168</td>\n",
       "      <td>0.461832</td>\n",
       "      <td>404004.0</td>\n",
       "      <td>37718.0</td>\n",
       "      <td>0.042269</td>\n",
       "      <td>0.048917</td>\n",
       "      <td>0.078905</td>\n",
       "      <td>...</td>\n",
       "      <td>3039.149268</td>\n",
       "      <td>386.163097</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13084.0</td>\n",
       "      <td>2948.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.349570</td>\n",
       "      <td>0.349689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.542135</td>\n",
       "      <td>0.457865</td>\n",
       "      <td>416870.0</td>\n",
       "      <td>39366.0</td>\n",
       "      <td>0.079154</td>\n",
       "      <td>0.093722</td>\n",
       "      <td>0.174337</td>\n",
       "      <td>...</td>\n",
       "      <td>2191.360052</td>\n",
       "      <td>350.848653</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11362.0</td>\n",
       "      <td>2948.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.863817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.537102</td>\n",
       "      <td>0.462898</td>\n",
       "      <td>404774.0</td>\n",
       "      <td>38238.0</td>\n",
       "      <td>0.038678</td>\n",
       "      <td>0.044894</td>\n",
       "      <td>0.072406</td>\n",
       "      <td>...</td>\n",
       "      <td>2816.240430</td>\n",
       "      <td>377.484669</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13084.0</td>\n",
       "      <td>2948.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.283542</td>\n",
       "      <td>0.283656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid  num_outgoing  num_incoming  outgoing_ratio  incoming_ratio  \\\n",
       "0  56.0         157.0         133.0        0.541379        0.458621   \n",
       "1  56.0         183.0         169.0        0.519886        0.480114   \n",
       "2  56.0         141.0         121.0        0.538168        0.461832   \n",
       "3  56.0         193.0         163.0        0.542135        0.457865   \n",
       "4  56.0         152.0         131.0        0.537102        0.462898   \n",
       "\n",
       "   outgoing_bytes  incoming_bytes  avg_outgoing_freq  avg_incoming_freq  \\\n",
       "0        414308.0         40486.0           0.042547           0.050559   \n",
       "1        417216.0         43430.0           0.182481           0.197864   \n",
       "2        404004.0         37718.0           0.042269           0.048917   \n",
       "3        416870.0         39366.0           0.079154           0.093722   \n",
       "4        404774.0         38238.0           0.038678           0.044894   \n",
       "\n",
       "   std_outgoing_freq  ...  std_outgoing_bytes  std_incoming_bytes  \\\n",
       "0           0.078255  ...         2958.765773          376.784956   \n",
       "1           0.517925  ...         2576.499100          351.063178   \n",
       "2           0.078905  ...         3039.149268          386.163097   \n",
       "3           0.174337  ...         2191.360052          350.848653   \n",
       "4           0.072406  ...         2816.240430          377.484669   \n",
       "\n",
       "   min_outgoing_bytes  min_incoming_bytes  max_outgoing_bytes  \\\n",
       "0                52.0                52.0             14532.0   \n",
       "1                52.0                52.0             14532.0   \n",
       "2                52.0                52.0             13084.0   \n",
       "3                52.0                52.0             11362.0   \n",
       "4                52.0                52.0             13084.0   \n",
       "\n",
       "   max_incoming_bytes  min_outgoing_freq  min_incoming_freq  \\\n",
       "0              2948.0           0.000024           0.000023   \n",
       "1              2948.0           0.000019           0.000030   \n",
       "2              2948.0           0.000007           0.000041   \n",
       "3              2948.0           0.000006           0.000025   \n",
       "4              2948.0           0.000022           0.000019   \n",
       "\n",
       "   max_outgoing_freq  max_incoming_freq  \n",
       "0           0.277571           0.320129  \n",
       "1           3.837083           3.837594  \n",
       "2           0.349570           0.349689  \n",
       "3           0.819853           0.863817  \n",
       "4           0.283542           0.283656  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the training data which is a numpy array of shape(5000,11) to a pandas dataframe\n",
    "df = pd.DataFrame(training_data, columns=[\n",
    "    'grid',\n",
    "    'num_outgoing',\n",
    "    'num_incoming',\n",
    "    'outgoing_ratio',\n",
    "    'incoming_ratio',\n",
    "    'outgoing_bytes',\n",
    "    'incoming_bytes',\n",
    "    'avg_outgoing_freq',\n",
    "    'avg_incoming_freq',\n",
    "    'std_outgoing_freq',\n",
    "    'std_incoming_freq',\n",
    "    'avg_outgoing_bytes',\n",
    "    'avg_incoming_bytes',\n",
    "    'std_outgoing_bytes',\n",
    "    'std_incoming_bytes',\n",
    "    'min_outgoing_bytes',\n",
    "    'min_incoming_bytes',\n",
    "    'max_outgoing_bytes',\n",
    "    'max_incoming_bytes',\n",
    "    'min_outgoing_freq',\n",
    "    'min_incoming_freq',\n",
    "    'max_outgoing_freq',\n",
    "    'max_incoming_freq'\n",
    "])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the unique grids in the dataset?\n",
    "label_count = len(df['grid'].unique())\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before feature selection:  (3200, 22)\n",
      "After feature selection:  (3200, 10)\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 4.2795 - sparse_categorical_accuracy: 0.0444 - val_loss: 4.1705 - val_sparse_categorical_accuracy: 0.0625\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 3.7138 - sparse_categorical_accuracy: 0.1166 - val_loss: 3.7271 - val_sparse_categorical_accuracy: 0.1450\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 3.3399 - sparse_categorical_accuracy: 0.1928 - val_loss: 3.3334 - val_sparse_categorical_accuracy: 0.2463\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3.0472 - sparse_categorical_accuracy: 0.2537 - val_loss: 3.0244 - val_sparse_categorical_accuracy: 0.3100\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.8026 - sparse_categorical_accuracy: 0.3088 - val_loss: 2.7962 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.6270 - sparse_categorical_accuracy: 0.3425 - val_loss: 2.6229 - val_sparse_categorical_accuracy: 0.3988\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.4742 - sparse_categorical_accuracy: 0.3681 - val_loss: 2.4945 - val_sparse_categorical_accuracy: 0.4200\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.3658 - sparse_categorical_accuracy: 0.3966 - val_loss: 2.3880 - val_sparse_categorical_accuracy: 0.4300\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.2692 - sparse_categorical_accuracy: 0.4069 - val_loss: 2.3071 - val_sparse_categorical_accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.1769 - sparse_categorical_accuracy: 0.4206 - val_loss: 2.2308 - val_sparse_categorical_accuracy: 0.4712\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.1072 - sparse_categorical_accuracy: 0.4391 - val_loss: 2.1630 - val_sparse_categorical_accuracy: 0.4762\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.0679 - sparse_categorical_accuracy: 0.4250 - val_loss: 2.1109 - val_sparse_categorical_accuracy: 0.4812\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.9992 - sparse_categorical_accuracy: 0.4469 - val_loss: 2.0734 - val_sparse_categorical_accuracy: 0.5063\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.9542 - sparse_categorical_accuracy: 0.4541 - val_loss: 2.0244 - val_sparse_categorical_accuracy: 0.5025\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.8982 - sparse_categorical_accuracy: 0.4747 - val_loss: 1.9882 - val_sparse_categorical_accuracy: 0.5025\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.8681 - sparse_categorical_accuracy: 0.4791 - val_loss: 1.9333 - val_sparse_categorical_accuracy: 0.5250\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.8310 - sparse_categorical_accuracy: 0.4831 - val_loss: 1.9122 - val_sparse_categorical_accuracy: 0.5125\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.7761 - sparse_categorical_accuracy: 0.4888 - val_loss: 1.8901 - val_sparse_categorical_accuracy: 0.5138\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.7642 - sparse_categorical_accuracy: 0.4928 - val_loss: 1.8496 - val_sparse_categorical_accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.7294 - sparse_categorical_accuracy: 0.5034 - val_loss: 1.8241 - val_sparse_categorical_accuracy: 0.5163\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.6957 - sparse_categorical_accuracy: 0.5084 - val_loss: 1.8062 - val_sparse_categorical_accuracy: 0.5362\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.6589 - sparse_categorical_accuracy: 0.5094 - val_loss: 1.7764 - val_sparse_categorical_accuracy: 0.5475\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.6685 - sparse_categorical_accuracy: 0.5184 - val_loss: 1.7655 - val_sparse_categorical_accuracy: 0.5512\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.6311 - sparse_categorical_accuracy: 0.5269 - val_loss: 1.7465 - val_sparse_categorical_accuracy: 0.5400\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.6182 - sparse_categorical_accuracy: 0.5163 - val_loss: 1.7303 - val_sparse_categorical_accuracy: 0.5612\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.5874 - sparse_categorical_accuracy: 0.5241 - val_loss: 1.7115 - val_sparse_categorical_accuracy: 0.5487\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.5587 - sparse_categorical_accuracy: 0.5278 - val_loss: 1.6957 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.5432 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.6726 - val_sparse_categorical_accuracy: 0.5700\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.5365 - sparse_categorical_accuracy: 0.5394 - val_loss: 1.6682 - val_sparse_categorical_accuracy: 0.5587\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.5070 - sparse_categorical_accuracy: 0.5512 - val_loss: 1.6726 - val_sparse_categorical_accuracy: 0.5587\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4955 - sparse_categorical_accuracy: 0.5456 - val_loss: 1.6524 - val_sparse_categorical_accuracy: 0.5625\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4725 - sparse_categorical_accuracy: 0.5537 - val_loss: 1.6362 - val_sparse_categorical_accuracy: 0.5738\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4681 - sparse_categorical_accuracy: 0.5575 - val_loss: 1.6218 - val_sparse_categorical_accuracy: 0.5663\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4623 - sparse_categorical_accuracy: 0.5559 - val_loss: 1.6128 - val_sparse_categorical_accuracy: 0.5788\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4289 - sparse_categorical_accuracy: 0.5659 - val_loss: 1.6077 - val_sparse_categorical_accuracy: 0.5713\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4382 - sparse_categorical_accuracy: 0.5672 - val_loss: 1.5938 - val_sparse_categorical_accuracy: 0.5800\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3883 - sparse_categorical_accuracy: 0.5641 - val_loss: 1.6064 - val_sparse_categorical_accuracy: 0.5775\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4010 - sparse_categorical_accuracy: 0.5759 - val_loss: 1.6049 - val_sparse_categorical_accuracy: 0.5725\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3829 - sparse_categorical_accuracy: 0.5731 - val_loss: 1.5717 - val_sparse_categorical_accuracy: 0.5900\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3761 - sparse_categorical_accuracy: 0.5703 - val_loss: 1.5621 - val_sparse_categorical_accuracy: 0.5975\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3644 - sparse_categorical_accuracy: 0.5734 - val_loss: 1.5719 - val_sparse_categorical_accuracy: 0.5975\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3414 - sparse_categorical_accuracy: 0.5769 - val_loss: 1.5598 - val_sparse_categorical_accuracy: 0.5875\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3609 - sparse_categorical_accuracy: 0.5716 - val_loss: 1.5535 - val_sparse_categorical_accuracy: 0.5925\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3316 - sparse_categorical_accuracy: 0.5944 - val_loss: 1.5480 - val_sparse_categorical_accuracy: 0.5938\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3316 - sparse_categorical_accuracy: 0.5891 - val_loss: 1.5511 - val_sparse_categorical_accuracy: 0.5875\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2979 - sparse_categorical_accuracy: 0.5913 - val_loss: 1.5417 - val_sparse_categorical_accuracy: 0.5975\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.3178 - sparse_categorical_accuracy: 0.5859 - val_loss: 1.5441 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2856 - sparse_categorical_accuracy: 0.6031 - val_loss: 1.5383 - val_sparse_categorical_accuracy: 0.6112\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2874 - sparse_categorical_accuracy: 0.6037 - val_loss: 1.5173 - val_sparse_categorical_accuracy: 0.6100\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2863 - sparse_categorical_accuracy: 0.5941 - val_loss: 1.5229 - val_sparse_categorical_accuracy: 0.6062\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2810 - sparse_categorical_accuracy: 0.5881 - val_loss: 1.5211 - val_sparse_categorical_accuracy: 0.5975\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2667 - sparse_categorical_accuracy: 0.6022 - val_loss: 1.5085 - val_sparse_categorical_accuracy: 0.6150\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2624 - sparse_categorical_accuracy: 0.5928 - val_loss: 1.4970 - val_sparse_categorical_accuracy: 0.6212\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2521 - sparse_categorical_accuracy: 0.5984 - val_loss: 1.4929 - val_sparse_categorical_accuracy: 0.6125\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2592 - sparse_categorical_accuracy: 0.5938 - val_loss: 1.5086 - val_sparse_categorical_accuracy: 0.6125\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2427 - sparse_categorical_accuracy: 0.6053 - val_loss: 1.4913 - val_sparse_categorical_accuracy: 0.6125\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2537 - sparse_categorical_accuracy: 0.6006 - val_loss: 1.5013 - val_sparse_categorical_accuracy: 0.6187\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2249 - sparse_categorical_accuracy: 0.6134 - val_loss: 1.4870 - val_sparse_categorical_accuracy: 0.6212\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2246 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.4940 - val_sparse_categorical_accuracy: 0.6212\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2156 - sparse_categorical_accuracy: 0.6031 - val_loss: 1.4902 - val_sparse_categorical_accuracy: 0.6200\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.2161 - sparse_categorical_accuracy: 0.6078 - val_loss: 1.4823 - val_sparse_categorical_accuracy: 0.6288\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.1922 - sparse_categorical_accuracy: 0.6153 - val_loss: 1.4796 - val_sparse_categorical_accuracy: 0.6137\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.2018 - sparse_categorical_accuracy: 0.6119 - val_loss: 1.4801 - val_sparse_categorical_accuracy: 0.6263\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.1803 - sparse_categorical_accuracy: 0.6144 - val_loss: 1.4761 - val_sparse_categorical_accuracy: 0.6237\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.1813 - sparse_categorical_accuracy: 0.6112 - val_loss: 1.4633 - val_sparse_categorical_accuracy: 0.6313\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1984 - sparse_categorical_accuracy: 0.6106 - val_loss: 1.4647 - val_sparse_categorical_accuracy: 0.6175\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1920 - sparse_categorical_accuracy: 0.6150 - val_loss: 1.4679 - val_sparse_categorical_accuracy: 0.6263\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1598 - sparse_categorical_accuracy: 0.6294 - val_loss: 1.4540 - val_sparse_categorical_accuracy: 0.6275\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1591 - sparse_categorical_accuracy: 0.6225 - val_loss: 1.4629 - val_sparse_categorical_accuracy: 0.6275\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1521 - sparse_categorical_accuracy: 0.6263 - val_loss: 1.4493 - val_sparse_categorical_accuracy: 0.6225\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1557 - sparse_categorical_accuracy: 0.6266 - val_loss: 1.4332 - val_sparse_categorical_accuracy: 0.6300\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1388 - sparse_categorical_accuracy: 0.6259 - val_loss: 1.4367 - val_sparse_categorical_accuracy: 0.6350\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1425 - sparse_categorical_accuracy: 0.6247 - val_loss: 1.4491 - val_sparse_categorical_accuracy: 0.6375\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1436 - sparse_categorical_accuracy: 0.6372 - val_loss: 1.4293 - val_sparse_categorical_accuracy: 0.6275\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1503 - sparse_categorical_accuracy: 0.6241 - val_loss: 1.4467 - val_sparse_categorical_accuracy: 0.6363\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1313 - sparse_categorical_accuracy: 0.6316 - val_loss: 1.4517 - val_sparse_categorical_accuracy: 0.6263\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1074 - sparse_categorical_accuracy: 0.6400 - val_loss: 1.4470 - val_sparse_categorical_accuracy: 0.6263\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1292 - sparse_categorical_accuracy: 0.6219 - val_loss: 1.4286 - val_sparse_categorical_accuracy: 0.6225\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1260 - sparse_categorical_accuracy: 0.6231 - val_loss: 1.4323 - val_sparse_categorical_accuracy: 0.6300\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1084 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.4336 - val_sparse_categorical_accuracy: 0.6288\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1240 - sparse_categorical_accuracy: 0.6247 - val_loss: 1.4390 - val_sparse_categorical_accuracy: 0.6300\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0971 - sparse_categorical_accuracy: 0.6372 - val_loss: 1.4406 - val_sparse_categorical_accuracy: 0.6350\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0863 - sparse_categorical_accuracy: 0.6491 - val_loss: 1.4265 - val_sparse_categorical_accuracy: 0.6300\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1148 - sparse_categorical_accuracy: 0.6300 - val_loss: 1.4305 - val_sparse_categorical_accuracy: 0.6425\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0786 - sparse_categorical_accuracy: 0.6469 - val_loss: 1.4149 - val_sparse_categorical_accuracy: 0.6275\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.1074 - sparse_categorical_accuracy: 0.6313 - val_loss: 1.4339 - val_sparse_categorical_accuracy: 0.6187\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0874 - sparse_categorical_accuracy: 0.6494 - val_loss: 1.4263 - val_sparse_categorical_accuracy: 0.6438\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0935 - sparse_categorical_accuracy: 0.6328 - val_loss: 1.4383 - val_sparse_categorical_accuracy: 0.6438\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0660 - sparse_categorical_accuracy: 0.6366 - val_loss: 1.4256 - val_sparse_categorical_accuracy: 0.6313\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0769 - sparse_categorical_accuracy: 0.6400 - val_loss: 1.4261 - val_sparse_categorical_accuracy: 0.6413\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0827 - sparse_categorical_accuracy: 0.6434 - val_loss: 1.4231 - val_sparse_categorical_accuracy: 0.6263\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0899 - sparse_categorical_accuracy: 0.6341 - val_loss: 1.4231 - val_sparse_categorical_accuracy: 0.6450\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0659 - sparse_categorical_accuracy: 0.6522 - val_loss: 1.4399 - val_sparse_categorical_accuracy: 0.6363\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0723 - sparse_categorical_accuracy: 0.6394 - val_loss: 1.4235 - val_sparse_categorical_accuracy: 0.6438\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0708 - sparse_categorical_accuracy: 0.6456 - val_loss: 1.4258 - val_sparse_categorical_accuracy: 0.6313\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0254 - sparse_categorical_accuracy: 0.6597 - val_loss: 1.4242 - val_sparse_categorical_accuracy: 0.6363\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0544 - sparse_categorical_accuracy: 0.6416 - val_loss: 1.4107 - val_sparse_categorical_accuracy: 0.6463\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0629 - sparse_categorical_accuracy: 0.6363 - val_loss: 1.4020 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0232 - sparse_categorical_accuracy: 0.6581 - val_loss: 1.4157 - val_sparse_categorical_accuracy: 0.6325\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0392 - sparse_categorical_accuracy: 0.6506 - val_loss: 1.4135 - val_sparse_categorical_accuracy: 0.6425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x45fe4ea40>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a grid search for different tebnsorflow models with different number of layers and neurons\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop('grid', axis=1)\n",
    "y = df['grid']\n",
    "\n",
    "# stratify the data to ensure that the training and testing sets have the same distribution of grids\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "# validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Before feature selection: \", X_train.shape)\n",
    "selector = SelectFromModel(RandomForestClassifier().fit(X_train, y_train), prefit=True)\n",
    "X_train = selector.transform(X_train)\n",
    "X_val = selector.transform(X_val)\n",
    "X_test = selector.transform(X_test)\n",
    "print(\"After feature selection: \", X_train.shape)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(label_count, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4753 - sparse_categorical_accuracy: 0.6380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.475314736366272, 0.6380000114440918]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid search for different tebnsorflow models with different number of layers and neurons\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# use multiple cores\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "X = df.drop('grid', axis=1)\n",
    "y = df['grid']\n",
    "\n",
    "# stratify the data to ensure that the training and testing sets have the same distribution of grids\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "# split the train into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "class SavedModels:\n",
    "    accuracy = 0\n",
    "    model = None\n",
    "    layers = None\n",
    "\n",
    "# number of cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "best_models = []\n",
    "for i in range(num_cores):\n",
    "    best_models.append(SavedModels())\n",
    "\n",
    "\n",
    "# training one layer\n",
    "def train_model(layers):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    for layer in layers:\n",
    "        type = layer[0]\n",
    "        value = layer[1]\n",
    "        if type == 'dense':\n",
    "            model.add(Dense(value, activation='relu'))\n",
    "        elif type == 'dropout':\n",
    "            model.add(Dropout(value))\n",
    "        elif type == 'batchnorm':\n",
    "            model.add(BatchNormalization())\n",
    "    model.add(Dense(label_count, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    # evaluate the model\n",
    "    _, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    return model, accuracy\n",
    "\n",
    "def train_chunk(chunk):\n",
    "    bestModel = SavedModels()\n",
    "    for i, layers in enumerate(chunk):\n",
    "        print(f\"Training model {i} of {len(chunk)}\")\n",
    "        model, accuracy = train_model(layers)\n",
    "        print(f\"Layer: {layers}, Accuracy: {accuracy}\")\n",
    "        if accuracy > bestModel.accuracy:\n",
    "            bestModel.accuracy = accuracy\n",
    "            bestModel.model = model\n",
    "            bestModel.layers = layers\n",
    "    return bestModel.accuracy, bestModel.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "# number of cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "layer_options = ['dense', 'batchnorm', 'dropout']\n",
    "layer_values = [16, 32, 64, 128]\n",
    "layers_list = []\n",
    "# create the list of all possible ways to create a model with 1-6 layers\n",
    "# length 1: 4 possible models [(dense, 16)], [(dense, 32)], [(dense, 64)], [(dense, 128)]\n",
    "# length 2: 16 possible models: [(dense 16), (dense 16)], [(dense 16), (dense 32)], [(dense 16), (dense 64)], [(dense 16), (dense 128)], [(dense 32), (dense 16)], [(dense 32), (dense 32)], [(dense 32), (dense 64)], [(dense 32), (dense 128)], [(dense 64), (dense 16)], [(dense 64), (dense 32)], [(dense 64), (dense 64)], [(dense 64), (dense 128)], [(dense 128), (dense 16)], [(dense 128), (dense 32)], [(dense 128), (dense 64)], [(dense 128), (dense 128)]\n",
    "# and so on\n",
    "for i in range(1, 5):\n",
    "    temp = list(itertools.product(layer_options, layer_values, repeat=i))\n",
    "    for t in temp:\n",
    "        tuples = []\n",
    "        skip = False\n",
    "        for i in range(0, len(t), 2):\n",
    "            if(t[i] == 'dropout'):\n",
    "                if(t[i+1] == 16):\n",
    "                    tuples.append((t[i], 0.1))\n",
    "                elif(t[i+1] == 32):\n",
    "                    tuples.append((t[i], 0.2))\n",
    "                elif(t[i+1] == 64):\n",
    "                    tuples.append((t[i], 0.3))\n",
    "                else:\n",
    "                    skip = True\n",
    "                    break\n",
    "            elif(t[i] == 'batchnorm'):\n",
    "                if (t[i + 1] == 16):\n",
    "                    tuples.append((t[i], 0))\n",
    "                else:\n",
    "                    skip = True\n",
    "                    break\n",
    "            else:\n",
    "                tuples.append((t[i], t[i+1]))\n",
    "        if skip:\n",
    "            continue\n",
    "        if len(tuples) == 1:\n",
    "            if tuples[0][0] == 'dropout' or tuples[0][0] == 'batchnorm':\n",
    "                continue\n",
    "        elif len(tuples) == 0:\n",
    "            continue\n",
    "        layers_list.append(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Divide the layers list into equal chunks\n",
    "layers_chunks = np.array_split(layers_list, num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 of 468\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Training model 0 of 468\n",
      "Training model 0 of 467\n",
      "Training model 0 of 468\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Training model 0 of 468\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Training model 0 of 467\n",
      "Training model 0 of 468\n",
      "Training model 0 of 468\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Training model 0 of 467\n",
      "Training model 0 of 467\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 00:12:41.490181: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.554380: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.583308: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.589986: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.590110: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.590700: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.595953: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.600753: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.607374: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-22 00:12:41.613346: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: [('dense', 16)], Accuracy: 0.5412499904632568\n",
      "Training model 1 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 64), ('dense', 16)], Accuracy: 0.3675000071525574\n",
      "Training model 1 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 16), ('dropout', 0.3)], Accuracy: 0.5174999833106995\n",
      "Training model 1 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.1), ('dropout', 0.1)], Accuracy: 0.41749998927116394\n",
      "Training model 1 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dense', 128), ('dense', 64)], Accuracy: 0.18125000596046448\n",
      "Training model 1 of 467\n",
      "Layer: [('dense', 32), ('batchnorm', 0), ('dropout', 0.3), ('dense', 16)], Accuracy: 0.5062500238418579\n",
      "Training model 1 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('batchnorm', 0), ('dense', 16)], Accuracy: 0.19875000417232513\n",
      "Training model 1 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.2), ('batchnorm', 0)], Accuracy: 0.5887500047683716\n",
      "Training model 1 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 32), ('batchnorm', 0)], Accuracy: 0.6324999928474426\n",
      "Training model 1 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('batchnorm', 0), ('batchnorm', 0)], Accuracy: 0.5562499761581421\n",
      "Training model 1 of 468\n",
      "Layer: [('dense', 32)], Accuracy: 0.5637500286102295\n",
      "Training model 2 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 64), ('dense', 32)], Accuracy: 0.3774999976158142\n",
      "Training model 2 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.1), ('dropout', 0.2)], Accuracy: 0.4300000071525574\n",
      "Training model 2 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 32), ('dense', 16)], Accuracy: 0.17374999821186066\n",
      "Training model 2 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dense', 128), ('dense', 128)], Accuracy: 0.11999999731779099\n",
      "Training model 2 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.2), ('dropout', 0.1)], Accuracy: 0.550000011920929\n",
      "Training model 2 of 467\n",
      "Layer: [('dense', 32), ('batchnorm', 0), ('dropout', 0.3), ('dense', 32)], Accuracy: 0.543749988079071\n",
      "Training model 2 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('batchnorm', 0), ('dense', 32)], Accuracy: 0.17125000059604645\n",
      "Training model 2 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('batchnorm', 0), ('dropout', 0.1)], Accuracy: 0.5612499713897705\n",
      "Training model 2 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 32), ('dropout', 0.1)], Accuracy: 0.5924999713897705\n",
      "Training model 2 of 468\n",
      "Layer: [('dense', 64)], Accuracy: 0.5912500023841858\n",
      "Training model 3 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 64), ('dense', 64)], Accuracy: 0.38749998807907104\n",
      "Training model 3 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.1), ('dropout', 0.3)], Accuracy: 0.4012500047683716\n",
      "Training model 3 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 32), ('dense', 32)], Accuracy: 0.17749999463558197\n",
      "Training model 3 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dense', 128), ('batchnorm', 0)], Accuracy: 0.5049999952316284\n",
      "Training model 3 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.2), ('dropout', 0.2)], Accuracy: 0.5587499737739563\n",
      "Training model 3 of 467\n",
      "Layer: [('dense', 32), ('batchnorm', 0), ('dropout', 0.3), ('dense', 64)], Accuracy: 0.4975000023841858\n",
      "Training model 3 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('batchnorm', 0), ('dense', 64)], Accuracy: 0.1574999988079071\n",
      "Training model 3 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('batchnorm', 0), ('dropout', 0.2)], Accuracy: 0.5600000023841858\n",
      "Training model 3 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 32), ('dropout', 0.2)], Accuracy: 0.6075000166893005\n",
      "Training model 3 of 468\n",
      "Layer: [('dense', 128)], Accuracy: 0.5950000286102295\n",
      "Training model 4 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 64), ('dense', 128)], Accuracy: 0.35374999046325684\n",
      "Training model 4 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.2), ('dense', 16)], Accuracy: 0.3812499940395355\n",
      "Training model 4 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 32), ('dense', 64)], Accuracy: 0.20874999463558197\n",
      "Training model 4 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dense', 128), ('dropout', 0.1)], Accuracy: 0.4325000047683716\n",
      "Training model 4 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.2), ('dropout', 0.3)], Accuracy: 0.5662500262260437\n",
      "Training model 4 of 467\n",
      "Layer: [('dense', 32), ('batchnorm', 0), ('dropout', 0.3), ('dense', 128)], Accuracy: 0.40625\n",
      "Training model 4 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('batchnorm', 0), ('dense', 128)], Accuracy: 0.09875000268220901\n",
      "Training model 4 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('batchnorm', 0), ('dropout', 0.3)], Accuracy: 0.5475000143051147\n",
      "Training model 4 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 32), ('dropout', 0.3)], Accuracy: 0.6087499856948853\n",
      "Training model 4 of 468\n",
      "Layer: [('dense', 16), ('dense', 16)], Accuracy: 0.48374998569488525\n",
      "Training model 5 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 64), ('batchnorm', 0)], Accuracy: 0.4975000023841858\n",
      "Training model 5 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.2), ('dense', 32)], Accuracy: 0.36250001192092896\n",
      "Training model 5 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 32), ('dense', 128)], Accuracy: 0.1525000035762787\n",
      "Training model 5 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dense', 128), ('dropout', 0.2)], Accuracy: 0.39500001072883606\n",
      "Training model 5 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.3), ('dense', 16)], Accuracy: 0.23250000178813934\n",
      "Training model 5 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.1), ('dense', 16)], Accuracy: 0.48249998688697815\n",
      "Training model 5 of 468\n",
      "Layer: [('dense', 16), ('dense', 32)], Accuracy: 0.45875000953674316\n",
      "Training model 6 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 64), ('dense', 16)], Accuracy: 0.061250001192092896\n",
      "Training model 5 of 468\n",
      "Layer: [('dense', 32), ('batchnorm', 0), ('dropout', 0.3), ('batchnorm', 0)], Accuracy: 0.5837500095367432\n",
      "Training model 5 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('batchnorm', 0), ('batchnorm', 0)], Accuracy: 0.5762500166893005\n",
      "Training model 5 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 64), ('dropout', 0.1)], Accuracy: 0.5212500095367432\n",
      "Training model 6 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.2), ('dense', 64)], Accuracy: 0.3725000023841858\n",
      "Training model 6 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dense', 128), ('dropout', 0.3)], Accuracy: 0.4337500035762787\n",
      "Training model 6 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 32), ('batchnorm', 0)], Accuracy: 0.5562499761581421\n",
      "Training model 6 of 467\n",
      "Layer: [('dense', 16), ('dense', 64)], Accuracy: 0.4412499964237213\n",
      "Training model 7 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.1), ('dense', 32)], Accuracy: 0.47999998927116394\n",
      "Training model 6 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.3), ('dense', 32)], Accuracy: 0.21875\n",
      "Training model 6 of 467\n",
      "Layer: [('dense', 32), ('batchnorm', 0), ('dropout', 0.3), ('dropout', 0.1)], Accuracy: 0.59375\n",
      "Training model 6 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 64), ('dense', 32)], Accuracy: 0.07750000059604645\n",
      "Training model 6 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('batchnorm', 0), ('dropout', 0.1)], Accuracy: 0.6050000190734863\n",
      "Training model 6 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 64), ('dropout', 0.2)], Accuracy: 0.5274999737739563\n",
      "Training model 7 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.2), ('dense', 128)], Accuracy: 0.26625001430511475\n",
      "Training model 7 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 32), ('dropout', 0.1)], Accuracy: 0.4975000023841858\n",
      "Training model 7 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('batchnorm', 0), ('dense', 16)], Accuracy: 0.4637500047683716\n",
      "Training model 7 of 467\n",
      "Layer: [('dense', 16), ('dense', 128)], Accuracy: 0.39625000953674316\n",
      "Training model 8 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.1), ('dense', 64)], Accuracy: 0.45124998688697815\n",
      "Training model 7 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.3), ('dense', 64)], Accuracy: 0.2787500023841858\n",
      "Training model 7 of 467\n",
      "Layer: [('dense', 32), ('batchnorm', 0), ('dropout', 0.3), ('dropout', 0.2)], Accuracy: 0.5912500023841858\n",
      "Training model 7 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 64), ('dense', 64)], Accuracy: 0.08124999701976776\n",
      "Training model 7 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('batchnorm', 0), ('dropout', 0.2)], Accuracy: 0.6162499785423279\n",
      "Training model 7 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 64), ('dropout', 0.3)], Accuracy: 0.5362499952316284\n",
      "Training model 8 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.2), ('batchnorm', 0)], Accuracy: 0.38624998927116394\n",
      "Training model 8 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('batchnorm', 0), ('dense', 32)], Accuracy: 0.4124999940395355\n",
      "Training model 8 of 467\n",
      "Layer: [('dense', 16), ('batchnorm', 0)], Accuracy: 0.5899999737739563\n",
      "Training model 9 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 32), ('dropout', 0.2)], Accuracy: 0.543749988079071\n",
      "Training model 8 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.1), ('dense', 128)], Accuracy: 0.44749999046325684\n",
      "Training model 8 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.3), ('dense', 128)], Accuracy: 0.2524999976158142\n",
      "Training model 8 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 128), ('dense', 16)], Accuracy: 0.3412500023841858\n",
      "Training model 9 of 468\n",
      "Layer: [('dense', 32), ('batchnorm', 0), ('dropout', 0.3), ('dropout', 0.3)], Accuracy: 0.574999988079071\n",
      "Training model 8 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 64), ('dense', 128)], Accuracy: 0.06499999761581421\n",
      "Training model 8 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('batchnorm', 0), ('dropout', 0.3)], Accuracy: 0.6324999928474426\n",
      "Training model 8 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.2), ('dropout', 0.1)], Accuracy: 0.4050000011920929\n",
      "Training model 9 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1)], Accuracy: 0.5137500166893005\n",
      "Training model 10 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('batchnorm', 0), ('dense', 64)], Accuracy: 0.4050000011920929\n",
      "Training model 9 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 32), ('dropout', 0.3)], Accuracy: 0.5687500238418579\n",
      "Training model 9 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.1), ('batchnorm', 0)], Accuracy: 0.5325000286102295\n",
      "Training model 9 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 128), ('dense', 32)], Accuracy: 0.3712500035762787\n",
      "Training model 10 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.3), ('batchnorm', 0)], Accuracy: 0.5649999976158142\n",
      "Training model 9 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 16), ('dense', 16)], Accuracy: 0.21875\n",
      "Training model 9 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.1), ('dense', 16)], Accuracy: 0.1862500011920929\n",
      "Training model 9 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.2), ('dropout', 0.2)], Accuracy: 0.4337500035762787\n",
      "Training model 10 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 64), ('batchnorm', 0)], Accuracy: 0.643750011920929\n",
      "Training model 9 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.2)], Accuracy: 0.512499988079071\n",
      "Training model 11 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 64), ('dense', 16)], Accuracy: 0.21375000476837158\n",
      "Training model 10 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.1), ('dropout', 0.1)], Accuracy: 0.5262500047683716\n",
      "Training model 10 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('batchnorm', 0), ('dense', 128)], Accuracy: 0.3712500035762787\n",
      "Training model 10 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 128), ('dense', 64)], Accuracy: 0.3425000011920929\n",
      "Training model 11 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.3), ('dropout', 0.1)], Accuracy: 0.5387499928474426\n",
      "Training model 10 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 16), ('dense', 32)], Accuracy: 0.17499999701976776\n",
      "Training model 10 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.2), ('dropout', 0.3)], Accuracy: 0.4050000011920929\n",
      "Training model 11 of 467\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.1), ('dense', 32)], Accuracy: 0.15625\n",
      "Training model 10 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.3)], Accuracy: 0.49125000834465027\n",
      "Training model 12 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 64), ('dropout', 0.1)], Accuracy: 0.5149999856948853\n",
      "Training model 10 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 64), ('dense', 32)], Accuracy: 0.1850000023841858\n",
      "Training model 11 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.1), ('dropout', 0.2)], Accuracy: 0.5062500238418579\n",
      "Training model 11 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('batchnorm', 0), ('batchnorm', 0)], Accuracy: 0.48374998569488525\n",
      "Training model 11 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 16), ('dense', 64)], Accuracy: 0.14624999463558197\n",
      "Training model 11 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.3), ('dropout', 0.2)], Accuracy: 0.5537499785423279\n",
      "Training model 11 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.3), ('dense', 16)], Accuracy: 0.3087500035762787\n",
      "Training model 12 of 467\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.1), ('dense', 64)], Accuracy: 0.14499999582767487\n",
      "Training model 11 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 128), ('dense', 128)], Accuracy: 0.32124999165534973\n",
      "Training model 12 of 468\n",
      "Layer: [('dense', 32), ('dense', 16)], Accuracy: 0.4975000023841858\n",
      "Training model 13 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 64), ('dropout', 0.2)], Accuracy: 0.5212500095367432\n",
      "Training model 11 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.1), ('dropout', 0.3)], Accuracy: 0.5074999928474426\n",
      "Training model 12 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 64), ('dense', 64)], Accuracy: 0.1537500023841858\n",
      "Training model 12 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('batchnorm', 0), ('dropout', 0.1)], Accuracy: 0.4975000023841858\n",
      "Training model 12 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.3), ('dense', 32)], Accuracy: 0.3387500047683716\n",
      "Training model 13 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 16), ('dense', 128)], Accuracy: 0.1887499988079071\n",
      "Training model 12 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 64), ('dropout', 0.3), ('dropout', 0.3)], Accuracy: 0.5425000190734863\n",
      "Training model 12 of 467\n",
      "Layer: [('dense', 32), ('dense', 32)], Accuracy: 0.42250001430511475\n",
      "Training model 14 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.1), ('dense', 128)], Accuracy: 0.07374999672174454\n",
      "Training model 12 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 128), ('batchnorm', 0)], Accuracy: 0.42875000834465027\n",
      "Training model 13 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 64), ('dropout', 0.3)], Accuracy: 0.5724999904632568\n",
      "Training model 12 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.2), ('dense', 16)], Accuracy: 0.47999998927116394\n",
      "Training model 13 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 64), ('dense', 128)], Accuracy: 0.10625000298023224\n",
      "Training model 13 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.3), ('dense', 64)], Accuracy: 0.32499998807907104\n",
      "Training model 14 of 467\n",
      "Layer: [('dense', 32), ('dense', 64)], Accuracy: 0.4300000071525574\n",
      "Training model 15 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('batchnorm', 0), ('dropout', 0.2)], Accuracy: 0.4712499976158142\n",
      "Training model 13 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 16), ('batchnorm', 0)], Accuracy: 0.6162499785423279\n",
      "Training model 13 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 128), ('dropout', 0.1)], Accuracy: 0.5412499904632568\n",
      "Training model 14 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 16), ('dense', 16)], Accuracy: 0.125\n",
      "Training model 13 of 467\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.1), ('batchnorm', 0)], Accuracy: 0.5887500047683716\n",
      "Training model 13 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 128), ('dense', 16)], Accuracy: 0.04125000163912773\n",
      "Training model 13 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.2), ('dense', 32)], Accuracy: 0.4699999988079071\n",
      "Training model 14 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 64), ('batchnorm', 0)], Accuracy: 0.5537499785423279\n",
      "Training model 14 of 467\n",
      "Layer: [('dense', 32), ('dense', 128)], Accuracy: 0.3987500071525574\n",
      "Training model 16 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.3), ('dense', 128)], Accuracy: 0.2487500011920929\n",
      "Training model 15 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 128), ('dropout', 0.2)], Accuracy: 0.5662500262260437\n",
      "Training model 15 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 16), ('dropout', 0.1)], Accuracy: 0.5487499833106995\n",
      "Training model 14 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('batchnorm', 0), ('dropout', 0.3)], Accuracy: 0.48875001072883606\n",
      "Training model 14 of 467\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.1), ('dropout', 0.1)], Accuracy: 0.45875000953674316\n",
      "Training model 14 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 16), ('dense', 32)], Accuracy: 0.11500000208616257\n",
      "Training model 14 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.2), ('dense', 64)], Accuracy: 0.4000000059604645\n",
      "Training model 15 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 128), ('dense', 32)], Accuracy: 0.05624999850988388\n",
      "Training model 14 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 64), ('dropout', 0.1)], Accuracy: 0.5237500071525574\n",
      "Training model 15 of 467\n",
      "Layer: [('dense', 32), ('batchnorm', 0)], Accuracy: 0.6137499809265137\n",
      "Training model 17 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 128), ('dropout', 0.3)], Accuracy: 0.5550000071525574\n",
      "Training model 16 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.3), ('batchnorm', 0)], Accuracy: 0.39375001192092896\n",
      "Training model 16 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 16), ('dropout', 0.2)], Accuracy: 0.5325000286102295\n",
      "Training model 15 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.1), ('dense', 16)], Accuracy: 0.38624998927116394\n",
      "Training model 15 of 467\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.1), ('dropout', 0.2)], Accuracy: 0.3824999928474426\n",
      "Training model 15 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 16), ('dense', 64)], Accuracy: 0.06875000149011612\n",
      "Training model 15 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.2), ('dense', 128)], Accuracy: 0.38874998688697815\n",
      "Training model 16 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 64), ('dropout', 0.2)], Accuracy: 0.4962500035762787\n",
      "Training model 16 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 128), ('dense', 64)], Accuracy: 0.07249999791383743\n",
      "Training model 15 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.1)], Accuracy: 0.5687500238418579\n",
      "Training model 18 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.3), ('dropout', 0.1)], Accuracy: 0.3987500071525574\n",
      "Training model 17 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 16), ('dropout', 0.3)], Accuracy: 0.5400000214576721\n",
      "Training model 16 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.1), ('dense', 32)], Accuracy: 0.3700000047683716\n",
      "Training model 16 of 467\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.1), ('dropout', 0.3)], Accuracy: 0.42375001311302185\n",
      "Training model 16 of 468\n",
      "Layer: [('dropout', 0.2), ('batchnorm', 0), ('dense', 16)], Accuracy: 0.4312500059604645\n",
      "Training model 17 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 16), ('dense', 128)], Accuracy: 0.10499999672174454\n",
      "Training model 16 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.2), ('batchnorm', 0)], Accuracy: 0.5149999856948853\n",
      "Training model 17 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 64), ('dropout', 0.3)], Accuracy: 0.5249999761581421\n",
      "Training model 17 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.2)], Accuracy: 0.5550000071525574\n",
      "Training model 19 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 128), ('dense', 128)], Accuracy: 0.06499999761581421\n",
      "Training model 16 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.3), ('dropout', 0.2)], Accuracy: 0.4012500047683716\n",
      "Training model 18 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.1), ('dense', 64)], Accuracy: 0.3474999964237213\n",
      "Training model 17 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 32), ('dense', 16)], Accuracy: 0.23125000298023224\n",
      "Training model 17 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.2), ('dense', 16)], Accuracy: 0.11999999731779099\n",
      "Training model 17 of 468\n",
      "Layer: [('dropout', 0.2), ('batchnorm', 0), ('dense', 32)], Accuracy: 0.42250001430511475\n",
      "Training model 18 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 16), ('batchnorm', 0)], Accuracy: 0.5612499713897705\n",
      "Training model 17 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.2), ('dropout', 0.1)], Accuracy: 0.5062500238418579\n",
      "Training model 18 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.3)], Accuracy: 0.5512499809265137\n",
      "Training model 20 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 128), ('dense', 16)], Accuracy: 0.17125000059604645\n",
      "Training model 18 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 16), ('dropout', 0.3), ('dropout', 0.3)], Accuracy: 0.4099999964237213\n",
      "Training model 19 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.1), ('dense', 128)], Accuracy: 0.36625000834465027\n",
      "Training model 18 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 128), ('batchnorm', 0)], Accuracy: 0.5912500023841858\n",
      "Training model 17 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 32), ('dense', 32)], Accuracy: 0.20749999582767487\n",
      "Training model 18 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.2), ('dense', 32)], Accuracy: 0.15125000476837158\n",
      "Training model 18 of 468\n",
      "Layer: [('dropout', 0.2), ('batchnorm', 0), ('dense', 64)], Accuracy: 0.44999998807907104\n",
      "Training model 19 of 468\n",
      "Layer: [('dense', 64), ('dense', 16)], Accuracy: 0.48124998807907104\n",
      "Training model 21 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.2), ('dropout', 0.2)], Accuracy: 0.4975000023841858\n",
      "Training model 19 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 16), ('dropout', 0.1)], Accuracy: 0.543749988079071\n",
      "Training model 18 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 128), ('dense', 32)], Accuracy: 0.2199999988079071\n",
      "Training model 19 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 16), ('dense', 16)], Accuracy: 0.2150000035762787\n",
      "Training model 20 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 32), ('dense', 64)], Accuracy: 0.17624999582767487\n",
      "Training model 19 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.1), ('batchnorm', 0)], Accuracy: 0.4650000035762787\n",
      "Training model 19 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 128), ('dropout', 0.1)], Accuracy: 0.41749998927116394\n",
      "Training model 18 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.2), ('dense', 64)], Accuracy: 0.07874999940395355\n",
      "Training model 19 of 468\n",
      "Layer: [('dropout', 0.2), ('batchnorm', 0), ('dense', 128)], Accuracy: 0.45500001311302185\n",
      "Training model 20 of 468\n",
      "Layer: [('dense', 64), ('dense', 32)], Accuracy: 0.4325000047683716\n",
      "Training model 22 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.2), ('dropout', 0.3)], Accuracy: 0.4950000047683716\n",
      "Training model 20 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 128), ('dense', 64)], Accuracy: 0.14000000059604645\n",
      "Training model 20 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 16), ('dropout', 0.2)], Accuracy: 0.5350000262260437\n",
      "Training model 19 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 16), ('dense', 32)], Accuracy: 0.22624999284744263\n",
      "Training model 21 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.1), ('dropout', 0.1)], Accuracy: 0.4950000047683716\n",
      "Training model 20 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 32), ('dense', 128)], Accuracy: 0.20624999701976776\n",
      "Training model 20 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.2), ('dense', 128)], Accuracy: 0.09624999761581421\n",
      "Training model 20 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 128), ('dropout', 0.2)], Accuracy: 0.4000000059604645\n",
      "Training model 19 of 468\n",
      "Layer: [('dense', 64), ('dense', 64)], Accuracy: 0.42625001072883606\n",
      "Training model 23 of 468\n",
      "Layer: [('dropout', 0.2), ('batchnorm', 0), ('batchnorm', 0)], Accuracy: 0.41749998927116394\n",
      "Training model 21 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.3), ('dense', 16)], Accuracy: 0.4312500059604645\n",
      "Training model 21 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 128), ('dense', 128)], Accuracy: 0.08624999970197678\n",
      "Training model 21 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 16), ('dropout', 0.3)], Accuracy: 0.5274999737739563\n",
      "Training model 20 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 16), ('dense', 64)], Accuracy: 0.1887499988079071\n",
      "Training model 22 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.1), ('dropout', 0.2)], Accuracy: 0.5024999976158142\n",
      "Training model 21 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 32), ('batchnorm', 0)], Accuracy: 0.6424999833106995\n",
      "Training model 21 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.2), ('batchnorm', 0)], Accuracy: 0.6025000214576721\n",
      "Training model 21 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dense', 128), ('dropout', 0.3)], Accuracy: 0.4399999976158142\n",
      "Training model 20 of 468\n",
      "Layer: [('dense', 64), ('dense', 128)], Accuracy: 0.42500001192092896\n",
      "Training model 24 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.3), ('dense', 32)], Accuracy: 0.41624999046325684\n",
      "Training model 22 of 468\n",
      "Layer: [('dropout', 0.2), ('batchnorm', 0), ('dropout', 0.1)], Accuracy: 0.38874998688697815\n",
      "Training model 22 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 128), ('batchnorm', 0)], Accuracy: 0.5224999785423279\n",
      "Training model 22 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 32), ('dense', 16)], Accuracy: 0.15125000476837158\n",
      "Training model 21 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 16), ('dense', 128)], Accuracy: 0.18125000596046448\n",
      "Training model 23 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.1), ('dropout', 0.3)], Accuracy: 0.49000000953674316\n",
      "Training model 22 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 32), ('dropout', 0.1)], Accuracy: 0.5362499952316284\n",
      "Training model 22 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.2), ('dropout', 0.1)], Accuracy: 0.4099999964237213\n",
      "Training model 22 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0)], Accuracy: 0.6075000166893005\n",
      "Training model 25 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('batchnorm', 0), ('dense', 16)], Accuracy: 0.47874999046325684\n",
      "Training model 21 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.3), ('dense', 64)], Accuracy: 0.3512499928474426\n",
      "Training model 23 of 468\n",
      "Layer: [('dropout', 0.2), ('batchnorm', 0), ('dropout', 0.2)], Accuracy: 0.40625\n",
      "Training model 23 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 128), ('dropout', 0.1)], Accuracy: 0.4112499952316284\n",
      "Training model 23 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 32), ('dense', 32)], Accuracy: 0.07500000298023224\n",
      "Training model 22 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.2), ('dense', 16)], Accuracy: 0.44999998807907104\n",
      "Training model 23 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 16), ('batchnorm', 0)], Accuracy: 0.4137499928474426\n",
      "Training model 24 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 32), ('dropout', 0.2)], Accuracy: 0.5375000238418579\n",
      "Training model 23 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.2), ('dropout', 0.2)], Accuracy: 0.4087499976158142\n",
      "Training model 23 of 468\n",
      "Layer: [('dense', 64), ('dropout', 0.1)], Accuracy: 0.5874999761581421\n",
      "Training model 26 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.3), ('dense', 128)], Accuracy: 0.33500000834465027\n",
      "Training model 24 of 468\n",
      "Layer: [('dropout', 0.2), ('batchnorm', 0), ('dropout', 0.3)], Accuracy: 0.39625000953674316\n",
      "Training model 24 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('batchnorm', 0), ('dense', 32)], Accuracy: 0.39250001311302185\n",
      "Training model 22 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 128), ('dropout', 0.2)], Accuracy: 0.4337500035762787\n",
      "Training model 24 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.2), ('dense', 32)], Accuracy: 0.4012500047683716\n",
      "Training model 24 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 16), ('dropout', 0.1)], Accuracy: 0.4675000011920929\n",
      "Training model 25 of 467\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 32), ('dense', 64)], Accuracy: 0.09875000268220901\n",
      "Training model 23 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 32), ('dropout', 0.3)], Accuracy: 0.5687500238418579\n",
      "Training model 24 of 468\n",
      "Layer: [('dense', 64), ('dropout', 0.2)], Accuracy: 0.5874999761581421\n",
      "Training model 27 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.2), ('dropout', 0.3)], Accuracy: 0.44999998807907104\n",
      "Training model 24 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.3), ('batchnorm', 0)], Accuracy: 0.48625001311302185\n",
      "Training model 25 of 468\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.1), ('dense', 16)], Accuracy: 0.45375001430511475\n",
      "Training model 25 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('dense', 128), ('dropout', 0.3)], Accuracy: 0.41999998688697815\n",
      "Training model 25 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.2), ('dense', 64)], Accuracy: 0.36250001192092896\n",
      "Training model 25 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('batchnorm', 0), ('dense', 64)], Accuracy: 0.4312500059604645\n",
      "Training model 23 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 16), ('dropout', 0.2)], Accuracy: 0.4424999952316284\n",
      "Training model 26 of 467\n",
      "Layer: [('dense', 64), ('dropout', 0.3)], Accuracy: 0.5874999761581421\n",
      "Training model 28 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 32), ('dense', 128)], Accuracy: 0.07500000298023224\n",
      "Training model 24 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 64), ('dense', 16)], Accuracy: 0.19499999284744263\n",
      "Training model 25 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.3), ('dense', 16)], Accuracy: 0.14374999701976776\n",
      "Training model 25 of 468\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.1), ('dense', 32)], Accuracy: 0.49000000953674316\n",
      "Training model 26 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.3), ('dropout', 0.1)], Accuracy: 0.4975000023841858\n",
      "Training model 26 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('batchnorm', 0), ('dense', 16)], Accuracy: 0.49000000953674316\n",
      "Training model 26 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.2), ('dense', 128)], Accuracy: 0.3824999928474426\n",
      "Training model 26 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 16), ('dropout', 0.3)], Accuracy: 0.39500001072883606\n",
      "Training model 27 of 467\n",
      "Layer: [('dense', 128), ('dense', 16)], Accuracy: 0.42250001430511475\n",
      "Training model 29 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('batchnorm', 0), ('dense', 128)], Accuracy: 0.36500000953674316\n",
      "Training model 24 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 64), ('dense', 32)], Accuracy: 0.2212499976158142\n",
      "Training model 26 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.3), ('dense', 32)], Accuracy: 0.12999999523162842\n",
      "Training model 26 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 32), ('batchnorm', 0)], Accuracy: 0.5687500238418579\n",
      "Training model 25 of 467\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.1), ('dense', 64)], Accuracy: 0.5024999976158142\n",
      "Training model 27 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.3), ('dropout', 0.2)], Accuracy: 0.48124998807907104\n",
      "Training model 27 of 468\n",
      "Layer: [('dense', 128), ('dense', 32)], Accuracy: 0.4362500011920929\n",
      "Training model 30 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('batchnorm', 0), ('dense', 32)], Accuracy: 0.4300000071525574\n",
      "Training model 27 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 32), ('dense', 16)], Accuracy: 0.21375000476837158\n",
      "Training model 28 of 467\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.2), ('batchnorm', 0)], Accuracy: 0.4749999940395355\n",
      "Training model 27 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 64), ('dense', 64)], Accuracy: 0.20000000298023224\n",
      "Training model 27 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.3), ('dense', 64)], Accuracy: 0.07249999791383743\n",
      "Training model 27 of 468\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.1), ('dense', 128)], Accuracy: 0.512499988079071\n",
      "Training model 28 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 32), ('dropout', 0.1)], Accuracy: 0.5062500238418579\n",
      "Training model 26 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('batchnorm', 0), ('batchnorm', 0)], Accuracy: 0.6225000023841858\n",
      "Training model 25 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.1), ('dropout', 0.3), ('dropout', 0.3)], Accuracy: 0.48374998569488525\n",
      "Training model 28 of 468\n",
      "Layer: [('dense', 128), ('dense', 64)], Accuracy: 0.41874998807907104\n",
      "Training model 31 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.2), ('dropout', 0.1)], Accuracy: 0.4975000023841858\n",
      "Training model 28 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 32), ('dense', 32)], Accuracy: 0.1899999976158142\n",
      "Training model 29 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('batchnorm', 0), ('dense', 64)], Accuracy: 0.3474999964237213\n",
      "Training model 28 of 467\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 64), ('dense', 128)], Accuracy: 0.1887499988079071\n",
      "Training model 28 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.3), ('dense', 128)], Accuracy: 0.06499999761581421\n",
      "Training model 28 of 468\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.1), ('batchnorm', 0)], Accuracy: 0.4037500023841858\n",
      "Training model 29 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 32), ('dropout', 0.2)], Accuracy: 0.5724999904632568\n",
      "Training model 27 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.2), ('dense', 16), ('dense', 16)], Accuracy: 0.16875000298023224\n",
      "Training model 29 of 468\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('batchnorm', 0), ('dropout', 0.1)], Accuracy: 0.625\n",
      "Training model 26 of 468\n",
      "Layer: [('dense', 128), ('dense', 128)], Accuracy: 0.39750000834465027\n",
      "Training model 32 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.2), ('dropout', 0.2)], Accuracy: 0.49125000834465027\n",
      "Training model 29 of 467\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 32), ('dense', 64)], Accuracy: 0.20749999582767487\n",
      "Training model 30 of 467\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('batchnorm', 0), ('dense', 128)], Accuracy: 0.32374998927116394\n",
      "Training model 29 of 467\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.1), ('dropout', 0.1)], Accuracy: 0.39500001072883606\n",
      "Training model 30 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 64), ('batchnorm', 0)], Accuracy: 0.643750011920929\n",
      "Training model 29 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.3), ('batchnorm', 0)], Accuracy: 0.6324999928474426\n",
      "Training model 29 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 32), ('dropout', 0.3)], Accuracy: 0.5375000238418579\n",
      "Training model 28 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.2), ('dense', 16), ('dense', 32)], Accuracy: 0.16750000417232513\n",
      "Training model 30 of 468\n",
      "Layer: [('dense', 128), ('batchnorm', 0)], Accuracy: 0.606249988079071\n",
      "Training model 33 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.2), ('dropout', 0.3)], Accuracy: 0.49125000834465027\n",
      "Training model 30 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('batchnorm', 0), ('dropout', 0.2)], Accuracy: 0.6225000023841858\n",
      "Training model 27 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 32), ('dense', 128)], Accuracy: 0.16500000655651093\n",
      "Training model 31 of 467\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.1), ('dropout', 0.2)], Accuracy: 0.4012500047683716\n",
      "Training model 31 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 64), ('dropout', 0.1)], Accuracy: 0.4987500011920929\n",
      "Training model 30 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('batchnorm', 0), ('batchnorm', 0)], Accuracy: 0.5537499785423279\n",
      "Training model 30 of 467\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.3), ('dropout', 0.1)], Accuracy: 0.39500001072883606\n",
      "Training model 30 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 64), ('dense', 16)], Accuracy: 0.07500000298023224\n",
      "Training model 29 of 467\n",
      "Layer: [('dense', 16), ('dropout', 0.2), ('dense', 16), ('dense', 64)], Accuracy: 0.14875000715255737\n",
      "Training model 31 of 468\n",
      "Layer: [('dense', 128), ('dropout', 0.1)], Accuracy: 0.6162499785423279\n",
      "Training model 34 of 468\n",
      "Layer: [('dropout', 0.2), ('dense', 32), ('dropout', 0.3), ('dense', 16)], Accuracy: 0.4112499952316284\n",
      "Training model 31 of 467\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.1), ('dropout', 0.3)], Accuracy: 0.3824999928474426\n",
      "Training model 32 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 32), ('batchnorm', 0)], Accuracy: 0.35499998927116394\n",
      "Training model 32 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('batchnorm', 0), ('dropout', 0.3)], Accuracy: 0.6237499713897705\n",
      "Training model 28 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 64), ('dropout', 0.2)], Accuracy: 0.5425000190734863\n",
      "Training model 31 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.3), ('dropout', 0.2)], Accuracy: 0.42875000834465027\n",
      "Training model 31 of 468\n",
      "Layer: [('dropout', 0.1), ('dense', 64), ('batchnorm', 0), ('dropout', 0.1)], Accuracy: 0.5387499928474426\n",
      "Training model 31 of 467\n",
      "Layer: [('dense', 128), ('dropout', 0.2)], Accuracy: 0.6187499761581421\n",
      "Training model 35 of 468\n",
      "Layer: [('dense', 16), ('dropout', 0.2), ('dense', 16), ('dense', 128)], Accuracy: 0.1574999988079071\n",
      "Training model 32 of 468\n",
      "Layer: [('batchnorm', 0), ('dense', 128), ('dense', 64), ('dense', 32)], Accuracy: 0.07124999910593033\n",
      "Training model 30 of 467\n",
      "Layer: [('dropout', 0.2), ('dropout', 0.2), ('dense', 16)], Accuracy: 0.4424999952316284\n",
      "Training model 33 of 468\n",
      "Layer: [('dropout', 0.3), ('dense', 32), ('dense', 32), ('dropout', 0.1)], Accuracy: 0.4362500011920929\n",
      "Training model 33 of 467\n",
      "Layer: [('dense', 64), ('batchnorm', 0), ('dropout', 0.1), ('dense', 16)], Accuracy: 0.45750001072883606\n",
      "Training model 29 of 468\n",
      "Layer: [('dense', 32), ('dropout', 0.1), ('dense', 64), ('dropout', 0.3)], Accuracy: 0.5074999928474426\n",
      "Training model 32 of 468\n",
      "Layer: [('dense', 128), ('dense', 128), ('dropout', 0.3), ('dropout', 0.3)], Accuracy: 0.42750000953674316\n",
      "Training model 32 of 468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Each core will train ONE chunk\n",
    "best_models = Parallel(n_jobs=num_cores)(delayed(train_chunk)(chunk) for chunk in layers_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for accuracy,layers in best_models:\n",
    "    print(f\"Accuracy: {accuracy}, Layers: {layers}\")\n",
    "    # print(model.model.evaluate(X_test, y_test, verbose=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
